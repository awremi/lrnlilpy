{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Big Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The term **big data** is notoriously vague: How big exactly does data need to be to be big? Nobody can give an exact quantification. However, the term is also intentionally fluid: _Data is big if that it poses so far unseen challenges, hitting the limits of traditional data processing approaches._ And depending on what these traditional approaches are (spreadsheet applications, databases, ...), different organizations have different threshold of big data. Still almost all organizations are facing increasing amounts of valuable data and the need to analyze it.\n",
    "\n",
    "Throughout this course we have already worked on strategies to deal with big data. One consequence of hitting the limits of applications (like Excel) is to work with a programming language (like Python). After that, other strategies are open. In this chapter, we discuss the most important of them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-Performance Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`numpy` and `pandas` are Python libraries. They provide a Python API that is \"pythonic\" - that is, adhering to the style and principles that Python programmers appreciate about the language. However, they are only partly written in Python. In order to work efficiently with large amounts of data, their core data structures and algorithms are not implemented in Python but in lower-level languages, C and C++. These are **compiled languages** that are translated to machine code that is run directly by the CPU (**\"native code\"**), rather than **interpreted languages** where the code is executed by a program (the interpreter). Compiled languages often allow for performance tuning \"close to the metal\", but they also often require close attention to very technical details of programming - in this case we speak of a **low-level language**. A **high-level language** like Python provides many useful abstractions and checks that make life easier for the programmer. A price to pay for that is that Python programs are comparatively slow.\n",
    "\n",
    "But there are ways to get the best of both worlds: Moving only the parts of the code that need to be high-performance to a low-level language while keeping the parts facing the application developer high-level. Libraries like `numpy`, `pandas` and `sklearn` all follow this strategy, and using them allows us to develop in Python while getting the performance of native code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example: Python Loops vs Numpy Array Operations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = range(int(1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423 ms ± 17.3 ms per loop (mean ± std. dev. of 7 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 5 [i**2 for i in values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.95 ms ± 735 µs per loop (mean ± std. dev. of 7 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "array = numpy.arange(int(1e6))\n",
    "%timeit -n 5 array**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programming and tuning code for maximum performance is a task for specialist developers. Being interested in the application side, often the best bet is to look for a well-tested, well-tuned implementation of the algorithm that we need. \n",
    "\n",
    "In some remaining cases, we need to code our own algorithms and optimize them for performance. While this is beyond the scope of this course, tools like **[Cython](http://cython.org/)** allow us to do this while staying in the Python world as much as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example: Compiling Blocks of Code with Cython Cell Magic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(n):\n",
    "    return [i**2 for i in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440 ms ± 22.3 ms per loop (mean ± std. dev. of 7 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 5 square(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "def square_(int n):\n",
    "    return [i**2 for i in range(n)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.1 ms ± 1.09 ms per loop (mean ± std. dev. of 7 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 5 square_(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared-Memory Parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clock frequency but increasing the number. parallelize among the cores of the CPU.\n",
    "\n",
    " workstations are available on-demand and at relatively low cost on several cloud computing platforms. \n",
    " \n",
    "For example, a workstation with 64 CPU cores and 500 GB or RAM readily available and an option to consider seriously. \n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if a data set is so large that it cannot fit into the memory of a single machine? collect and process many terabytes of data. \n",
    "\n",
    "**distributed computing**, or **distributed parallelism**.\n",
    "\n",
    "do not access a common RAM, exchanged via. While very fast networks exist for this purpose, network communication can be much slower than accessing the RAM.\n",
    "\n",
    "distributed parallelism has a certain overhead in comparison with shared-memory parallelism.\n",
    "\n",
    "\n",
    "additional , such as **partitioning**, how to split the data and computation over the nodes of cluster to maximize performance.\n",
    "\n",
    "To put it in simplistic terms: Big data tasks do not run fast _just because_ you run them on a cluster.\n",
    "\n",
    "A big advantage of distributed solutions is scalability: While there is often a hard limit to the RAM that can be installed in a single machine, a cluster can be scaled up simply by adding more machines. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://upload.wikimedia.org/wikipedia/commons/c/c5/MEGWARE.CLIC.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed Computing Frameworks\n",
    "\n",
    "Apache Spark.  Spark is written in Scala, a language for the Java Virtual Machine, and provides APIs in Scala, Java and Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing a Big Data Technology Stack\n",
    "\n",
    "- parallelism\n",
    "- scalability\n",
    "- maturity \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "_This notebook is licensed under a [Creative Commons Attribution 4.0 International License (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/). Copyright © 2018 [Point 8 GmbH](https://point-8.de)_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
