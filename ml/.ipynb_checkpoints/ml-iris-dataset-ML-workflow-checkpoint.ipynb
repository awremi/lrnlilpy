{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Machine Learning im Schnelldurchlauf\n",
    "Wir wollen nun einen schnellen Durchlauf durch den Machine Learning Workflow vornehmen. Sie werden sehen, dahinter steckt keine Magie und die Schritte sind nicht schwer. Auch werden Sie feststellen, dass man recht einfach zwischen verschiedenen Modellen wechseln kann, wenn man gewisse Standards einhält. Darüberhinaus lernen wir einen sehr wichtigen Teil bei der Anwendung kennen, denn Validierung ist mit eines der wichtigsten Schritte!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ressourcen zur Datenhaltung und einfache statistische Methoden\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import Markdown\n",
    "\n",
    "# Import der ML-Methoden und Validierung\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (roc_curve, roc_auc_score)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#Einstellungen zur Online-Darstellung von Grafiken innerhalb von Jupyter\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Datensätze für Machine Learning Beispiele\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dateneinlesen und Vorbereiten\n",
    "Hier lesen wir den Iris Datensatz ein, den wir schon aus unserer Einleitung kennen und wandeln ihn wieder in einen Pandas Dataframe um. Die Spaltenbeschriftung setzen wir ebenfalls. Wissen, was in der jeweiligen Spalte steht, ist aber oftmals schon die erste Hürde in der Analyse von echten Daten. Zusätzlich nimmt die weitere Vorbereitung der Daten oft 50% der Arbeit ein. Denn es gilt stets \"Bullshit in, bullshit out\"! Es muss u.a. auf Konsistenz geprüft werden, fehlende Daten ersetzt oder bereinigt werden, Formate kontrolliert werden, Textfelder in numerische Werte kodiert werden und vieles mehr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "#Einen Dataframe aus den Iris-Daten erstellen\n",
    "df = pd.DataFrame(iris.data)\n",
    "#Die Spalten des Dataframe richtig benennen\n",
    "df.columns = iris['feature_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "Im vorigen Notebook haben wir uns bereits empirisch die verschiedenen Features angeschaut und das Potential für die Trennung der verschiedenen Klassen erkannt. Für das Training unseres ML-Models müssen wir selektieren, welche Features (Eingangsgrößen) wir nutzen wollen, um auf unsere Klassen (Zielgrößen) zu schließen. In unserem Beispiel können wir alle nutzen, aber selbstverständlich auch nur einen Teil von ihnen. In der Wirklichkeit macht es Sinn möglichst aussagekräftige Features zu selektieren, gerade wenn man limitiert in der Rechenkapazität ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Auswahl der Features\n",
    "\n",
    "training_features = [\n",
    "    'sepal length (cm)', \n",
    "    'sepal width (cm)', \n",
    "    'petal length (cm)',\n",
    "    'petal width (cm)'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "Ganz ohne menschlichen Input geht es natürlich normalerweise nicht. Ein großer Teil der Datenvorbereitung ist neben dem Erkennen von aussagekräftigen Features auch das Generieren von zusätzlichen Features. Will man beispielsweise zweitabhängige Aussagen treffen, sollten die Features auch zeitabhängige Informationen tragen. Oder verläuft ein Wertebereich eines Features über mehrere Größenordnung macht es vielleicht Sinn die Skala mit einem Logarithmus zu transformieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition von Eingangs- und Zielgröße für ML\n",
    "Jetzt ist es an der Zeit die Eingangswerte und die Zielgrößen klar getrennt voneinander zu halten, damit man nicht versehentlich das Ergebnis in seinen Trainingsdaten hat. Wir wollen stets **$X$** für alle Eingangswerte und **$y$** für die Zielgröße nutzen.\n",
    "\n",
    "Zusätzlich machen wir einen kleinen Test auf Vollständigkeit und löschen alle Messungen, die fehlende Datenpunkte (NaN = not a number) aufweisen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df[training_features].dropna()\n",
    "y = pd.DataFrame(iris.target)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorarbeit für die Validierung\n",
    "Eine der Standardansätze für die Validierung ist das Auftrennen des Datensatzes in einen Training- und Testdatensatz. Dafür wird hier die Funktion `train_test_split` genutzt. Im Beispiel teilen wir den Datensatz genau in zwei Hälften. Hier sollte man stets beachten, dass Training- und Testdatensatz die gleichen Informationen tragen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sind die Daten nun gemischt?\n",
    "y_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "Das zugrundeliegende ML-Modell wird an dieser Stelle initialisiert. Hier sieht man schon den Vorteil, wenn man sich an gewissen Standards in der Definition hält. Man kann leicht zwischen verschiedenen Modellen wie neuronalen Netzen oder Entscheidungsbäumen wechseln. Ein wichtiger Bestandteil der Initialisierung ist das Setzen der Hyperparameter, deren Optimierung ein wichtiger Prozess sein wird, um die Performance zu steigern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=50, max_depth=2)\n",
    "#model = MLPClassifier(hidden_layer_sizes=(20,), activation='relu')\n",
    "#model = GradientBoostingClassifier(n_estimators=20, max_depth=2)\n",
    "#model = MLPClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting\n",
    "Das eigentliche Trainieren bzw. Fitting findet in einer Zeile statt. Man beachte, dass wir zum Trainieren auch nur den Trainingsdatensatz nutzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validierung\n",
    "\n",
    "### Ergebnisse und Begutachtung\n",
    "Das Modell ist nun trainiert und wir können es auch jeden beliebigen Datensatz anwenden. Wichtig für die Validierung wird es sein, sich gerade den Trainings- und Testdatensatz im Vergleich zu betrachten, damit man über die Performance und Übertragbarkeit (Generalisierung) entscheiden kann. Mit `model.predict_proba(dataset)` erhalten wir für jede Messung die Wahrscheinlichkeit für jeden einzelnen Schwertlilientyp. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_test = model.predict_proba(X_test)\n",
    "y_pred_train = model.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Wir haben für jede Messung drei Wahrscheinlichkeiten erhalten\n",
    "y_pred_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Summe der Wahrscheinlichkeiten ergibt stets genau eins\n",
    "y_pred_test.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Betrachtung der Wahrscheinlichkeit eines Blütentyps i\n",
    "i=2\n",
    "y_pred_test_i = y_pred_test[:,i]\n",
    "y_pred_train_i = y_pred_train[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Für alle 75 Messungen des Testdatensatzen haben wir nun die Wahrscheinlichkeit für Typ i\n",
    "y_pred_test_i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Wie viele gehören in Wirklichkeit zu Typ i\n",
    "y_pred_test_i[(y_test == i)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Wie hoch sind die jeweiligen Wahrscheinlichkeiten? Werden alle richtig zugeordnet? \n",
    "y_pred_test_i[(y_test == i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erhalten falsche Messungen hohe Wahrscheinlichkeiten für den Typ i (->False Positives)\n",
    "y_pred_test_i[(y_test != i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir zählen, wie viele eine Wahrscheinlichkeit größer 50 Prozent aufweisen.\n",
    "(y_pred_test_i > 0.5).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Wie viele gehören in Wirklichkeit zu Typ i\n",
    "y_pred_test_i[(y_test == i).values].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die mittleren Wahrscheinlichkeiten im Vergleich\n",
    "for i in range(3):\n",
    "    y_pred_test_i = y_pred_test[:,i]\n",
    "    type_i = y_pred_test_i[(y_test == i)].mean()\n",
    "    not_type_i = y_pred_test_i[(y_test != i)].mean()\n",
    "    print(f'Typ {i}: Mittlere Wahrscheinlichkeit für wahre {type_i:.2f} und unwahre {not_type_i:.2f} Vorhersagen.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesentest\n",
    "Sich nur Zahlen anzuschauen ist alles andere als übersichtlich. Es gibt aber einfache Tools und Vorgehensweisen, um sich die Ergebnisse besser zu visualisieren. Hier betrachten wir die Ergebnisse für jeden Typ einzeln. Wir brauchen also in diesem Beispiel drei einzelne Plots. Angegeben wird für jede Messungen die Wahrscheinlichkeit, dass sie zum jeweiligen Typ $i$ gehört. Man spricht auch von einem Hypothesentest in diesem Zusammenhang.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [0,1,2]:\n",
    "    y_pred_test_i = y_pred_test[:,i]\n",
    "    \n",
    "    plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    plt.hist(y_pred_test_i[(y_test == 0).values], bins=np.linspace(0,1,20), alpha=0.5, normed=False, label='Setosa')\n",
    "    plt.hist(y_pred_test_i[(y_test == 1).values], bins=np.linspace(0,1,20), alpha=0.5, normed=False, label='Versicolor')\n",
    "    plt.hist(y_pred_test_i[(y_test == 2).values], bins=np.linspace(0,1,20), alpha=0.5, normed=False, label='Virginica')\n",
    "\n",
    "    plt.legend()\n",
    "    \n",
    "    if i == 0:\n",
    "        plt.title('Hypothese: Messung gehört zu Typ 0: Iris Setosa')\n",
    "    elif i == 1:\n",
    "        plt.title('Hypothese: Messung gehört zu Typ 1: Iris Versicolor')\n",
    "    elif i == 2:\n",
    "        plt.title('Hypothese: Messung gehört zu Typ 2: Iris Virginica')\n",
    "    plt.xlabel('Wahrscheinlichkeit, dass die Hypothese wahr ist')\n",
    "    plt.ylabel('Anzahl')\n",
    "    \n",
    "    #plt.yscale('log',nonposy='clip')\n",
    "    #plt.ylabel('log(Anzahl)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Kurve\n",
    "Die Receiver Operating Characteristics (ROC) sind ein mächtiges Instrument zur Bewertung verschiedener Aspekte von ML-Modellen. Sie stellt die richtig-positiv Rate in Abhängigkeit der falsch-positiv Rate in einem Diagramm dar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    y_pred_test_i = y_pred_test[:,i]\n",
    "    y_pred_train_i = y_pred_train[:,i]\n",
    "    \n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.plot(*roc_curve(y_test == i, y_pred_test_i)[:2], label='test')\n",
    "    plt.plot(*roc_curve(y_train == i, y_pred_train_i)[:2], label='train')\n",
    "    plt.plot([-0.1, 1.1],[-0.1, 1.1], color='black', linestyle=':')\n",
    "    plt.title(f'ROC-Kurve Typ {i}')\n",
    "    plt.xlabel('falsch-positiv Rate')\n",
    "    plt.ylabel('richtig-positiv Rate') \n",
    "    plt.xlim(-0.05, 1.05)\n",
    "    plt.ylim(-0.05, 1.05)\n",
    "    plt.legend(loc='best')\n",
    "    plt.show();    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "In einer Confusion Matrix (Table of Confusion) wird für jede einzelne Klasse dargestellt, wie viele Messungen richtig zugeordnet werden (Hauptdiagonale) und wie viele falsch. Zusätzlich erkennt man auch zu welchem falschen Typ zugeordnet wird. Bei drei Klassen erhält man also eine 3x3 Matrix. Die Summe über die jeweilige Zeile ergibt die wahre Anzahl der Mitglieder pro Typ und die Summe über die Spalte die Anzahl vorhergesagter Mitglieder pro Typ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Liste mit den Klassenzugehörigkeiten\n",
    "highest_pred = model.predict(X_test)\n",
    "\n",
    "truth = y_test\n",
    "pred = highest_pred\n",
    "cm = confusion_matrix(truth, pred)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Summe der wahren Mitglieder (Zeile)\n",
    "(y_test.values==1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summe der vorhergesagten Mitglieder (Spalte)\n",
    "(highest_pred==1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hilfsfunktionen für die Kondensierung auf eine binäre Klassifizierung\n",
    "\n",
    "# Das komplette Modell wird übergeben\n",
    "def make_bina_class(model, X_sample, i, threshold=0.0, check_max=True):\n",
    "    proba = model.predict_proba(X_sample)\n",
    "    if check_max:\n",
    "        highest_pred = model.predict(X_sample)\n",
    "        bina_class = [0 if (pred == i) and (proba[pos][i] >= threshold) else 1 for pos, pred  in enumerate(highest_pred)]\n",
    "    else:\n",
    "        bina_class = [0 if (pred >= threshold) else 1 for pred in proba[:,i]]\n",
    "    return bina_class   \n",
    "\n",
    "# In der List Comprehension geschieht folgendes:\n",
    "   #for pos, pred  in enumerate(highest_pred):\n",
    "   #    if (pred == i) & (proba[pos][i] >= threshold):\n",
    "   #        bina_class.append(0)\n",
    "   #    else:\n",
    "   #        bina_class.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier wird die Confusion Matrix auf eine Hypothese, somit zu einer binären Klassifikation, kondensiert, sodass man für jede Kategorie eine 2x2 Matrix erhält. Die Summe der ersten Zeile sind alle wahren Mitglieder (**Positives**, P) des Typs, die sich aus den **True Positives** (TP) und **False Negatives** (FN) zusammensetzt. Die Summe der zweiten Zeile sind alle unwahren Mitglieder (**Negatives**, N), die sich aus der Summe der **False Positives** (FP) und **True Negatives** (TN) ergibt.\n",
    "\n",
    "| als Positive klassifiziert| als Negative klassifiziert\n",
    "-|-\n",
    "**Positives (P)** | True Positives (TP) | False Negatives (FN)\n",
    "**Negatives (N)** | False Positives (FP)  | True Negatives (TN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "truth = y_test\n",
    "pred = highest_pred\n",
    "cm = confusion_matrix(truth, pred)\n",
    "print(f'Confusion Matrix 3x3')\n",
    "print(cm)\n",
    "\n",
    "for i in range(3):\n",
    "    pred = make_bina_class(model, X_test, i)\n",
    "    truth_i = [0 if j == i else 1 for j in y_test]\n",
    "    cm= confusion_matrix(truth_i,pred)\n",
    "    print(f'\\n Typ {i}')\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC und Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weitere Kennzahlen sind zum Beispiel die Fläche unter der ROC Kurve (**A**rea **U**nder **C**urve **AUC**) oder die **Accuracy** $\\bigl(\\frac{TP + TN}{P + N}\\bigr)$. Sie gibt an, wie viele Messungen insgesamt richtig klassifiziert werden unabhängig, ob sie zu den Positives oder Negatives gehören. Bei der Accuracy muss man aber aufpassen, ob man eine Klasse oder alle Messungen betrachtet. Weitere wichtige Kennzahlen werden im späteren Verlauf betrachtet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste mit den Klassenzugehörigkeiten\n",
    "highest_pred = model.predict(X_test)\n",
    "\n",
    "# Wie viele werden falsch zugeordnet \n",
    "print(f'falsch klassifizierte Messungen: {(highest_pred != y_test).sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s = \"\"\"\n",
    "Typ | AUC | Accuracy\n",
    ":-:|:-:|:-:|:-:\n",
    "\"\"\" \n",
    "for i in range(3):\n",
    "    y_pred_test_i = y_pred_test[:,i]\n",
    "    \n",
    "    \n",
    "    roc = roc_auc_score(y_test.values == i, y_pred_test_i)\n",
    "    score = model.score(X_test[y_test.values == i], y_test[y_test.values == i])\n",
    "    \n",
    "    \n",
    "    # Betrachtung aller richtigen und falschen Zuordnungen\n",
    "    #to_check = np.logical_or(highest_pred==i , y_test==i)\n",
    "    #score = model.score(X_test[to_check], y_test[to_check])\n",
    "    \n",
    "    s += f'{i} | {roc:.3f} | {score:.3f} \\n'\n",
    " \n",
    "display(Markdown(s))\n",
    "display(Markdown(f\"**Mittlere Accuracy**: {model.score(X_test, y_test):.3f}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "Man kann sich leicht anzeigen lassen, welches Feature eine höhere Relevanz für den Klassifizierer hat. So kann bei einer Vielzahl an Features ihre Relevanz gegeneinander abgewägt werden, um den Rechenaufwand zu minimieren. Auf der anderen Seite können aber auch bisher unbekannte Features als wichtig eingestuft werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktioniert nur für GradientBoostingClassifier oder RandomForestClassifier\n",
    "if (str(model)[0:3] != 'MLP'):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.barh(range(len(X.columns)), model.feature_importances_)\n",
    "    plt.yticks(range(len(X.columns)), X.columns)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"So einfach funktioniert es leider nur für baumartige Classifier wie GradientBoostingClassifier oder RandomForestClassifier\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
